{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cp = pd.read_csv(\"../../dataset/processed/train_cleaned_v4_139k.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from category_encoders.target_encoder import TargetEncoder\n",
    "\n",
    "\n",
    "def clean(df, mode=\"test\"):\n",
    "    try:\n",
    "        df.drop([\"no_family_residing\"], axis=1, inplace=True)\n",
    "    except:\n",
    "        pass\n",
    "    ordinal_col = [\"land_surface_condition\", \"technical_solution_proposed\"]\n",
    "\n",
    "    binary_col = [\"flexible_superstructure\", \"public_place_type\",\n",
    "                \"govermental_use_type\", \"has_secondary_use\"]\n",
    "    numerical_col = [\"floors_before_eq (total)\", \"old_building\",\n",
    "                    \"plinth_area (ft^2)\", \"height_before_eq (ft)\"]\n",
    "    target_col = [\"damage_grade\"]\n",
    "    categorical_col_lt5 = [col for col in train_cp.columns if col not in ordinal_col +\n",
    "                        binary_col + numerical_col + target_col and train_cp[col].nunique() <= 4]\n",
    "    cat_col = [col for col in train_cp.columns if col not in ordinal_col +\n",
    "            binary_col + numerical_col + target_col and train_cp[col].nunique() >= 5]\n",
    "    angka = {\n",
    "        \"one\": 1,\n",
    "        \"two\": 2,\n",
    "        \"three\": 3,\n",
    "        \"four\": 4,\n",
    "        \"five\": 5,\n",
    "        \"six\": 6,\n",
    "        \"seven\": 7,\n",
    "        \"eight\": 8,\n",
    "        \"nine\": 9,\n",
    "        \"1st\": 1,\n",
    "        \"2nd\": 2,\n",
    "        \"3rd\": 3,\n",
    "        \"fifth\": 5,\n",
    "        \"second\": 2,\n",
    "        \"third\": 3,\n",
    "        \"3.00\": 3,\n",
    "    }\n",
    "\n",
    "    delete = {\n",
    "        \"story\": \"\",\n",
    "        \"stories\": \"\",\n",
    "        \"floor\": \"\",\n",
    "        \"floors\": \"\",\n",
    "        \"has\": \"\",\n",
    "        \"there is\": \"\",\n",
    "        \"just\": \"\",\n",
    "        \"-\": \"\",\n",
    "        \"fl\": \"\",\n",
    "        \"/\": \"\",\n",
    "    }\n",
    "\n",
    "    df[\"floors_before_eq (total)\"] = df[\"floors_before_eq (total)\"]\\\n",
    "        .str.lower()\\\n",
    "        .replace(delete, regex=True)\\\n",
    "        .str.strip()\\\n",
    "        .replace(angka, regex=True)\n",
    "\n",
    "    df[\"floors_before_eq (total)\"] = df[\"floors_before_eq (total)\"].astype(\n",
    "        \"float\")\n",
    "    df[\"plinth_area (ft^2)\"] = df[\"plinth_area (ft^2)\"].str.lower()\n",
    "\n",
    "    df[\"plinth_area (ft^2)\"] = df[\"plinth_area (ft^2)\"].apply(\n",
    "        lambda x: x.replace(\" ft^2\", \"\"))\n",
    "    df[\"plinth_area (ft^2)\"] = df[\"plinth_area (ft^2)\"].apply(\n",
    "        lambda x: x.replace(\"more than \", \"\"))\n",
    "    df[\"plinth_area (ft^2)\"] = df[\"plinth_area (ft^2)\"].astype(\n",
    "        \"float\")\n",
    "\n",
    "    type_of_foundation_dict = {\n",
    "        # \"Mud mortar-Stone/Brick\": \"Clay mortar-Stone/Brick\",\n",
    "        \"Bamboo/TImber\": \"Bamboo or Timber\",\n",
    "        \"Bamboo/Timber\": \"Bamboo or Timber\",\n",
    "        \"RC\": \"Reinforced Concrete\",\n",
    "        \"Others\": \"Other\",\n",
    "        \"Cement-Stone or Cement-Brick\": \"Cement-Stone/Brick\"\n",
    "    }\n",
    "\n",
    "    df[\"type_of_foundation\"] = df[\"type_of_foundation\"]\\\n",
    "        .replace(type_of_foundation_dict)\\\n",
    "        .str.strip()\n",
    "\n",
    "    type_of_roof_dict = {\n",
    "        \"Bamboo/TImber-Heavy Roof\": \"Bamboo/Timber Heavy roof\",\n",
    "        \"Bamboo/TImber-Light Roof\": \"Bamboo or Timber Light roof\",\n",
    "        \"Bamboo/Timber Light roof\": \"Bamboo or Timber Light roof \",\n",
    "        \"reinforced cement concrete/rb/rbc\": \"rcc/rb/rbc\",\n",
    "        \"Reinforced brick concrete/rcc/rbc\": \"rcc/rb/rbc\",\n",
    "        \"Bamboo or Timber Heavy roof\": \"Bamboo/Timber Heavy roof\",\n",
    "        \"Reinforced Brick Slab/rcc/rbc\": \"rcc/rb/rbc\",\n",
    "    }\n",
    "\n",
    "    df[\"type_of_roof\"] = df[\"type_of_roof\"].replace(\n",
    "        type_of_roof_dict).str.strip()\n",
    "\n",
    "    type_of_ground_floor_dict = {\n",
    "        \"rc\": \"reinforced concrete\",\n",
    "        \"brick/stone\": \"brick or stone\",\n",
    "        # \"lumber\": \"wood\",\n",
    "        # \"timber\": \"wood\",\n",
    "        # \"mud\": \"clay\"\n",
    "    }\n",
    "\n",
    "    df[\"type_of_ground_floor\"] = df[\"type_of_ground_floor\"].str.lower()\\\n",
    "        .replace(type_of_ground_floor_dict)\\\n",
    "\n",
    "\n",
    "    type_of_other_floor_dict = {\n",
    "        # \"lumber-plank\": \"wood-plank\",\n",
    "        # \"timber-planck\": \"wood-plank\",\n",
    "        \"timber/bamboo-mud\": \"wood-mud or bamboo mud\",\n",
    "        \"reinforced cement concrete/rb/rbc\": \"rcc/rb/rbc\",\n",
    "        \"wood or bamboo mud\": \"wood-mud or bamboo mud\",\n",
    "        \"timber mud or bamboo-mud\": \"wood-mud or bamboo mud\"\n",
    "    }\n",
    "\n",
    "    df[\"type_of_other_floor\"] = df[\"type_of_other_floor\"]\\\n",
    "        .str.lower()\\\n",
    "        .replace(type_of_other_floor_dict)\n",
    "\n",
    "    # df['no_family_residing'] = df['no_family_residing'].replace(\n",
    "    #     'None', '0.0').astype('float')\n",
    "\n",
    "    df[\"residential_type\"] = df[\"residential_type\"].replace({\n",
    "        \"Other Residential Type\": \"Other\"\n",
    "    })\n",
    "    df['govermental_use_type'] = df['govermental_use_type'].replace(\n",
    "        ['Police Offices'], 'Govermental Buildings')\n",
    "    df[\"public_place_type\"] = df[\"public_place_type\"]\\\n",
    "        .apply(lambda x: \"Public\" if x != \"Non-public\" else \"Non-public\")\n",
    "\n",
    "    legal_ownership_status_dict = {\n",
    "        \"Private\": \"Private\",\n",
    "        \"Private Use\": \"Private\",\n",
    "        \"Prvt\": \"Private\",\n",
    "        \"Privste\": \"Private\",\n",
    "        \"Public Use\": \"Public\",\n",
    "        \"Public Space\": \"Public\",\n",
    "        \"Institutional Use\": \"Institutional\",\n",
    "        \"Institutionals\": \"Institutional\",\n",
    "        \"Unknown\": \"Other\",\n",
    "        \"Unspecified\": \"Other\",\n",
    "    }\n",
    "\n",
    "    df[\"legal_ownership_status\"] = df[\"legal_ownership_status\"].str.strip(\n",
    "    ).replace(legal_ownership_status_dict)\n",
    "\n",
    "    land_surface_condition_dict = {\n",
    "        \"Steep slope\": 0,\n",
    "        \"Moderate slope\": 1,\n",
    "        \"Flat\": 2,\n",
    "    }\n",
    "\n",
    "    df[\"land_surface_condition\"] = df[\"land_surface_condition\"].replace(\n",
    "        land_surface_condition_dict)\n",
    "\n",
    "    technical_solution_proposed_dict = {\n",
    "        \"Reconstruction\": 0,\n",
    "        \"Major repair\": 1,\n",
    "        \"Minor repair\": 2,\n",
    "        \"No need\": 3,\n",
    "    }\n",
    "\n",
    "    df[\"technical_solution_proposed\"] = df[\"technical_solution_proposed\"].replace(\n",
    "        technical_solution_proposed_dict)\n",
    "\n",
    "    flexible_superstructure_dict = {\n",
    "        \"unavailable\": 0,\n",
    "        \"available\": 1,\n",
    "    }\n",
    "\n",
    "    df[\"flexible_superstructure\"] = df[\"flexible_superstructure\"].replace(\n",
    "        flexible_superstructure_dict)\n",
    "\n",
    "    public_place_type_dict = {\n",
    "        \"Public\": 0,\n",
    "        \"Non-public\": 1,\n",
    "    }\n",
    "\n",
    "    df[\"public_place_type\"] = df[\"public_place_type\"].replace(\n",
    "        public_place_type_dict)\n",
    "\n",
    "    governmental_use_type_dict = {\n",
    "        \"Govermental Buildings\": 0,\n",
    "        \"Non-govermental\": 1,\n",
    "    }\n",
    "\n",
    "    df[\"govermental_use_type\"] = df[\"govermental_use_type\"].replace(\n",
    "        governmental_use_type_dict)\n",
    "\n",
    "    # ohe_df = pd.DataFrame(ohe.transform(train_cp[categorical_col_lt5]))\n",
    "    # ohe_df.columns = ohe.get_feature_names(categorical_col_lt5)\n",
    "\n",
    "    # train_ohe = train_cp.copy()\n",
    "    # for cat in categorical_col_lt5:\n",
    "    #     train_ohe.drop(cat, axis=1, inplace=True)\n",
    "\n",
    "    # print(train_ohe.shape)\n",
    "\n",
    "    # train_ohe_merge = pd.concat([train_ohe, ohe_df], axis=1)\n",
    "\n",
    "    # print(train_ohe_merge.shape)\n",
    "    train_ohe_merge = df.copy()\n",
    "    # train_ohe_merge[numerical_col] = s.transform(\n",
    "    #     train_ohe_merge[numerical_col])\n",
    "\n",
    "    enc_df = train_ohe_merge.copy()\n",
    "    if mode == \"test\":\n",
    "        enc_df[cat_col + categorical_col_lt5] = enc.transform(\n",
    "            train_ohe_merge[cat_col + categorical_col_lt5])\n",
    "    else:\n",
    "        enc = TargetEncoder(cols=cat_col + categorical_col_lt5)\n",
    "        enc.fit(train_ohe_merge[cat_col + categorical_col_lt5],\n",
    "                train_ohe_merge[\"damage_grade\"])\n",
    "        enc_df[cat_col + categorical_col_lt5] = enc.transform(\n",
    "            train_ohe_merge[cat_col + categorical_col_lt5])\n",
    "\n",
    "    return enc_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "train_enc = clean(train_cp, mode=\"train\")\n",
    "\n",
    "X = train_enc.drop([\"damage_grade\"], axis=1)\n",
    "y = train_enc[\"damage_grade\"].copy()\n",
    "y -= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (104267, 22)\n",
      "X_test: (34756, 22)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=69420, stratify=y)\n",
    "\n",
    "print(f\"\"\"\\\n",
    "X_train: {X_train.shape}\n",
    "X_test: {X_test.shape}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 10:49:21,934]\u001b[0m A new study created in memory with name: no-name-c90c3d7c-bc2d-497f-b3fa-8332a4545c40\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:49:34,125]\u001b[0m Trial 2 finished with value: 0.646479245153788 and parameters: {'n_estimators': 49, 'max_depth': 51, 'min_samples_split': 8, 'min_samples_leaf': 7, 'max_features': 'log2'}. Best is trial 2 with value: 0.646479245153788.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:49:45,933]\u001b[0m Trial 5 finished with value: 0.6455516229852611 and parameters: {'n_estimators': 121, 'max_depth': 61, 'min_samples_split': 4, 'min_samples_leaf': 1, 'max_features': 'auto'}. Best is trial 2 with value: 0.646479245153788.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:49:54,157]\u001b[0m Trial 4 finished with value: 0.6486850978729032 and parameters: {'n_estimators': 203, 'max_depth': 77, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:49:55,068]\u001b[0m Trial 6 finished with value: 0.17595926063204034 and parameters: {'n_estimators': 785, 'max_depth': 1, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'log2'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:50:31,745]\u001b[0m Trial 9 finished with value: 0.6468279996780423 and parameters: {'n_estimators': 263, 'max_depth': 81, 'min_samples_split': 5, 'min_samples_leaf': 10, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:50:32,077]\u001b[0m Trial 8 finished with value: 0.6475713187790226 and parameters: {'n_estimators': 276, 'max_depth': 31, 'min_samples_split': 7, 'min_samples_leaf': 9, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:50:32,783]\u001b[0m Trial 0 finished with value: 0.6477531328887942 and parameters: {'n_estimators': 498, 'max_depth': 79, 'min_samples_split': 4, 'min_samples_leaf': 6, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:50:42,381]\u001b[0m Trial 10 finished with value: 0.6469375093901384 and parameters: {'n_estimators': 75, 'max_depth': 19, 'min_samples_split': 4, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:50:54,551]\u001b[0m Trial 13 finished with value: 0.6463473210081521 and parameters: {'n_estimators': 78, 'max_depth': 35, 'min_samples_split': 7, 'min_samples_leaf': 8, 'max_features': 'log2'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:51:14,920]\u001b[0m Trial 3 finished with value: 0.64777221684435 and parameters: {'n_estimators': 821, 'max_depth': 41, 'min_samples_split': 8, 'min_samples_leaf': 5, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:51:16,503]\u001b[0m Trial 7 finished with value: 0.6477336768643431 and parameters: {'n_estimators': 726, 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:51:18,308]\u001b[0m Trial 11 finished with value: 0.6481825920052076 and parameters: {'n_estimators': 509, 'max_depth': 10, 'min_samples_split': 9, 'min_samples_leaf': 5, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:51:34,533]\u001b[0m Trial 1 finished with value: 0.6485341012804156 and parameters: {'n_estimators': 956, 'max_depth': 32, 'min_samples_split': 3, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:52:29,827]\u001b[0m Trial 14 finished with value: 0.6471802438355796 and parameters: {'n_estimators': 781, 'max_depth': 92, 'min_samples_split': 10, 'min_samples_leaf': 10, 'max_features': 'log2'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:52:34,666]\u001b[0m Trial 15 finished with value: 0.6480844411568346 and parameters: {'n_estimators': 537, 'max_depth': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:52:36,511]\u001b[0m Trial 17 finished with value: 0.6479860084910196 and parameters: {'n_estimators': 540, 'max_depth': 97, 'min_samples_split': 10, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:52:51,776]\u001b[0m Trial 18 finished with value: 0.6484312334079199 and parameters: {'n_estimators': 564, 'max_depth': 100, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:52:54,434]\u001b[0m Trial 12 finished with value: 0.6480747709214032 and parameters: {'n_estimators': 988, 'max_depth': 87, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:53:27,557]\u001b[0m Trial 16 finished with value: 0.6485197611050911 and parameters: {'n_estimators': 911, 'max_depth': 97, 'min_samples_split': 9, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:53:41,260]\u001b[0m Trial 23 finished with value: 0.6480933596223843 and parameters: {'n_estimators': 315, 'max_depth': 66, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:54:24,519]\u001b[0m Trial 24 finished with value: 0.647447017344218 and parameters: {'n_estimators': 349, 'max_depth': 67, 'min_samples_split': 6, 'min_samples_leaf': 7, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:54:49,481]\u001b[0m Trial 25 finished with value: 0.6475900999995364 and parameters: {'n_estimators': 390, 'max_depth': 69, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:54:57,102]\u001b[0m Trial 19 finished with value: 0.6477202385649837 and parameters: {'n_estimators': 932, 'max_depth': 63, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:55:05,709]\u001b[0m Trial 20 finished with value: 0.6479305304956917 and parameters: {'n_estimators': 922, 'max_depth': 61, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:55:13,177]\u001b[0m Trial 21 finished with value: 0.6482510532277397 and parameters: {'n_estimators': 971, 'max_depth': 65, 'min_samples_split': 2, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:55:29,142]\u001b[0m Trial 22 finished with value: 0.6480908229539214 and parameters: {'n_estimators': 1000, 'max_depth': 64, 'min_samples_split': 6, 'min_samples_leaf': 3, 'max_features': 'auto'}. Best is trial 4 with value: 0.6486850978729032.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:56:50,325]\u001b[0m Trial 29 finished with value: 0.6493236506805762 and parameters: {'n_estimators': 654, 'max_depth': 76, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 29 with value: 0.6493236506805762.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:57:03,416]\u001b[0m Trial 26 finished with value: 0.6488436943377067 and parameters: {'n_estimators': 990, 'max_depth': 75, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 29 with value: 0.6493236506805762.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:57:05,678]\u001b[0m Trial 30 finished with value: 0.6493258978721903 and parameters: {'n_estimators': 702, 'max_depth': 47, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:57:10,694]\u001b[0m Trial 31 finished with value: 0.6488436943377067 and parameters: {'n_estimators': 646, 'max_depth': 77, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:57:14,568]\u001b[0m Trial 27 finished with value: 0.6490056218302968 and parameters: {'n_estimators': 937, 'max_depth': 51, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:57:18,196]\u001b[0m Trial 28 finished with value: 0.6488436943377067 and parameters: {'n_estimators': 894, 'max_depth': 51, 'min_samples_split': 3, 'min_samples_leaf': 4, 'max_features': 'auto'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:58:47,223]\u001b[0m Trial 32 finished with value: 0.6482555086632622 and parameters: {'n_estimators': 668, 'max_depth': 51, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'auto'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:58:48,508]\u001b[0m Trial 34 finished with value: 0.6479155595957045 and parameters: {'n_estimators': 630, 'max_depth': 51, 'min_samples_split': 5, 'min_samples_leaf': 6, 'max_features': 'log2'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:58:51,098]\u001b[0m Trial 33 finished with value: 0.6482555086632622 and parameters: {'n_estimators': 655, 'max_depth': 78, 'min_samples_split': 5, 'min_samples_leaf': 5, 'max_features': 'auto'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:58:57,263]\u001b[0m Trial 35 finished with value: 0.6479964854296594 and parameters: {'n_estimators': 654, 'max_depth': 53, 'min_samples_split': 7, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:58:58,792]\u001b[0m Trial 36 finished with value: 0.6484166083405783 and parameters: {'n_estimators': 651, 'max_depth': 52, 'min_samples_split': 3, 'min_samples_leaf': 5, 'max_features': 'auto'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 10:59:03,172]\u001b[0m Trial 37 finished with value: 0.6482332618604043 and parameters: {'n_estimators': 655, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'auto'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:00:05,739]\u001b[0m Trial 42 finished with value: 0.6471635154643693 and parameters: {'n_estimators': 435, 'max_depth': 41, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:00:08,451]\u001b[0m Trial 43 finished with value: 0.6493258978721903 and parameters: {'n_estimators': 450, 'max_depth': 43, 'min_samples_split': 6, 'min_samples_leaf': 4, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:00:18,311]\u001b[0m Trial 39 finished with value: 0.6485863433447517 and parameters: {'n_estimators': 621, 'max_depth': 43, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:00:36,467]\u001b[0m Trial 40 finished with value: 0.6478525866558857 and parameters: {'n_estimators': 853, 'max_depth': 44, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:00:36,946]\u001b[0m Trial 38 finished with value: 0.6491029265098296 and parameters: {'n_estimators': 881, 'max_depth': 42, 'min_samples_split': 3, 'min_samples_leaf': 2, 'max_features': 'log2'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:00:37,563]\u001b[0m Trial 41 finished with value: 0.6480311873465051 and parameters: {'n_estimators': 860, 'max_depth': 44, 'min_samples_split': 4, 'min_samples_leaf': 2, 'max_features': 'sqrt'}. Best is trial 30 with value: 0.6493258978721903.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def rf_objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 1, 100),\n",
    "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 10),\n",
    "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
    "        \"max_features\": trial.suggest_categorical(\"max_features\", [\"auto\", \"sqrt\", \"log2\"]),\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(**params, random_state=69420,  n_jobs=6)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    return f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(rf_objective, n_trials=100, timeout=600, n_jobs=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 702,\n",
       " 'max_depth': 47,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 4,\n",
       " 'max_features': 'auto'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-04-12 11:00:57,907]\u001b[0m A new study created in memory with name: no-name-f958a6fc-f5d9-4d73-84d2-f772ec58fa9f\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:02:02,293]\u001b[0m Trial 2 finished with value: 0.6490085020658836 and parameters: {'learning_rate': 0.01, 'n_estimators': 103, 'max_depth': 9}. Best is trial 2 with value: 0.6490085020658836.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:02:29,846]\u001b[0m Trial 0 finished with value: 0.6489523098551897 and parameters: {'learning_rate': 0.014, 'n_estimators': 261, 'max_depth': 6}. Best is trial 2 with value: 0.6490085020658836.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:03:36,004]\u001b[0m Trial 6 finished with value: 0.6486355833274727 and parameters: {'learning_rate': 0.018, 'n_estimators': 392, 'max_depth': 5}. Best is trial 2 with value: 0.6490085020658836.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:03:37,998]\u001b[0m Trial 5 finished with value: 0.648772994311064 and parameters: {'learning_rate': 0.01, 'n_estimators': 454, 'max_depth': 6}. Best is trial 2 with value: 0.6490085020658836.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:04:15,688]\u001b[0m Trial 3 finished with value: 0.649209544996486 and parameters: {'learning_rate': 0.008, 'n_estimators': 365, 'max_depth': 8}. Best is trial 3 with value: 0.649209544996486.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:05:23,959]\u001b[0m Trial 8 finished with value: 0.6497250474296357 and parameters: {'learning_rate': 0.016, 'n_estimators': 163, 'max_depth': 10}. Best is trial 8 with value: 0.6497250474296357.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:06:53,558]\u001b[0m Trial 10 finished with value: 0.6498019723756754 and parameters: {'learning_rate': 0.012, 'n_estimators': 409, 'max_depth': 7}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:07:16,023]\u001b[0m Trial 11 finished with value: 0.6497409472873866 and parameters: {'learning_rate': 0.014, 'n_estimators': 305, 'max_depth': 7}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:07:43,470]\u001b[0m Trial 7 finished with value: 0.649234056137094 and parameters: {'learning_rate': 0.02, 'n_estimators': 476, 'max_depth': 10}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:07:51,441]\u001b[0m Trial 4 finished with value: 0.6466378055542389 and parameters: {'learning_rate': 0.016, 'n_estimators': 372, 'max_depth': 14}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:09:25,261]\u001b[0m Trial 14 finished with value: 0.6495674083778705 and parameters: {'learning_rate': 0.02, 'n_estimators': 310, 'max_depth': 6}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:09:37,015]\u001b[0m Trial 1 finished with value: 0.6479805063156133 and parameters: {'learning_rate': 0.01, 'n_estimators': 498, 'max_depth': 13}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:09:51,212]\u001b[0m Trial 9 finished with value: 0.6467670490722811 and parameters: {'learning_rate': 0.016, 'n_estimators': 284, 'max_depth': 15}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:11:30,084]\u001b[0m Trial 16 finished with value: 0.6493638748753006 and parameters: {'learning_rate': 0.012, 'n_estimators': 225, 'max_depth': 8}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:11:57,371]\u001b[0m Trial 18 finished with value: 0.6492040166272575 and parameters: {'learning_rate': 0.012, 'n_estimators': 219, 'max_depth': 8}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:12:04,766]\u001b[0m Trial 17 finished with value: 0.6490601022891579 and parameters: {'learning_rate': 0.012, 'n_estimators': 287, 'max_depth': 8}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:12:29,351]\u001b[0m Trial 15 finished with value: 0.647806189144991 and parameters: {'learning_rate': 0.012, 'n_estimators': 231, 'max_depth': 14}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:12:43,611]\u001b[0m Trial 13 finished with value: 0.6490593111012092 and parameters: {'learning_rate': 0.018, 'n_estimators': 476, 'max_depth': 11}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n",
      "\u001b[32m[I 2023-04-12 11:12:57,711]\u001b[0m Trial 12 finished with value: 0.647684098312662 and parameters: {'learning_rate': 0.018, 'n_estimators': 423, 'max_depth': 13}. Best is trial 10 with value: 0.6498019723756754.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "def xgb_objective(trial):\n",
    "\n",
    "    params = {\n",
    "        # 'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n",
    "        # 'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n",
    "        'learning_rate': trial.suggest_categorical('learning_rate', [0.008, 0.01, 0.012, 0.014, 0.016, 0.018, 0.02]),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    return f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(xgb_objective, n_trials=100, n_jobs=6, timeout=600, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d3120404ab40088dde46363bad1bdd78d1aeca7b6f18e79999fc72cb3d9151a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
